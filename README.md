# Microsoft-Malware-Prediction
Overview
This project involves predicting malware infections on machines using a dataset provided by Microsoft on Kaggle. The goal is to develop and evaluate various machine learning models to classify whether a machine is infected or not. The dataset contains a variety of features related to machine configurations, software states, and other system details.

Dataset
The dataset is sourced from the Microsoft Malware Prediction competition on Kaggle. It consists of three main files:

train.csv: Training data with features and target labels.
test.csv: Test data with features only (for predictions).
sample_submission.csv: Sample submission file to guide the format of your predictions.
Features
The dataset includes both numerical and categorical features related to machine identifiers, product versions, operating system details, and more. Key features include:

Numerical Columns: Various attributes like IsBeta, RtpStateBitfield, AVProductsInstalled, and Census_TotalPhysicalRAM.
Categorical Columns: Identifiers and categorical variables like ProductName, EngineVersion, OsBuildLab, and Census_OSArchitecture.
Project Workflow
Data Loading: Read and inspect the dataset. Handle missing values and perform initial preprocessing.
Feature Engineering: Encode categorical variables, scale numerical features, and address skewness.
Dimensionality Reduction:
t-SNE: Applied for visualizing encoded features in a 2D space.
UMAP: Applied for further dimensionality reduction to 20 features.
Feature Selection:
Chi-Square Test: Identifies important categorical features.
ANOVA F-Score: Evaluates numerical features.
Mutual Information: Measures the dependency between features and the target variable.
Model Training and Evaluation:
Random Forest Classifier
XGBoost Classifier
LightGBM Classifier
AdaBoost Classifier
Gradient Boosting Classifier
Logistic Regression
SVM (Support Vector Machine)
Model Performance Metrics: Accuracy, ROC AUC, and F1 Score.
Code Implementation
The code performs the following steps:

GPU Check: Verify if a GPU is available for TensorFlow.
t-SNE Visualization: Apply t-SNE for visualizing encoded features.
Feature Selection:
Chi-Square test for categorical features.
ANOVA F-Score for numerical features.
Mutual Information for all features.
Dimensionality Reduction:
UMAP applied to reduce features to 20 dimensions.
Model Training:
Train and evaluate models using various classifiers.
Evaluation and Plotting:
Plot feature importances and model performance metrics.
Requirements
Python 3.x
TensorFlow
scikit-learn
Plotly
UMAP
XGBoost
LightGBM
Pandas
Matplotlib
Seaborn
